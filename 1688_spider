# coding=utf-8
import requests,time
from lxml import etree
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
from alibaba_1688sql import alibaba_Sql
import traceback
import json, jsonpath, re
import sys
reload(sys)
sys.setdefaultencoding("utf-8")
from hashlib import md5

class alibaba_spider(object):
    def __init__(self):
        self.start_url = "https://www.1688.com/"
        self.ali = alibaba_Sql()
        self.s = requests.Session()
        self.state_code = ''

        proxyHost = "n10.t.16yun.cn"
        proxyPort = "6442"
        proxyUser = "16SBYYUY"
        proxyPass = "658666"
        proxyMeta = "http://%(user)s:%(pass)s@%(host)s:%(port)s" % {
            "host": proxyHost,
            "port": proxyPort,
            "user": proxyUser,
            "pass": proxyPass,
        }
        print proxyMeta
        self.proxy = {
            "http": proxyMeta,
            "https": proxyMeta,
        }
        self.headers = {
            "Accept": "*/*",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Cache-Control": "max-age=0",
            "Connection": "keep-alive",
            "Pragma": "no-cache",
            # "Host":"h5api.m.1688.com",
            # "Referer": "http://m.1688.com/?src=desktop",
            "Referer": "https://m.1688.com/offer_search/-C1BFBEDF.html?spm=a26g8.7710019.0.0",
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 11_0 like Mac OS X) AppleWebKit/604.1.38 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1",
        }

    def categoryData(self):
        # 查询数据库原有的分类数据
        newCategory = set()
        sqlData = self.ali.get_categoryName()
        for cate_data in sqlData:
            newCategory.add(cate_data[0])

        response = self.s.get(self.start_url,verify=False)
        response.encoding = "utf-8"

        html_obj = etree.HTML(response.text)
        product_link_list = html_obj.xpath("//ul[@id='sub-nav']/li/a/@href")
        product_name_list = html_obj.xpath("//ul[@id='sub-nav']/li/a/text()")

        # 一级分类数据
        link_list = [link for link in product_link_list[:36]]
        name_list = [name for name in product_name_list[:36]]

        created_time = time.strftime("%Y-%m-%d %H:%M:%S")
        del link_list[17:19]
        del name_list[17:19]
        for link, name in zip(link_list, name_list):
            if "https:" not in link:
                p_link = "https:" + link
            else:
                p_link = link

            if name not in newCategory:
                newCategory.add(name)
                pid = self.ali.insert_category(name, p_link, 0, 1, created_time)
                _id = (self.ali.getId())[0][0]
                print 6666,_id
                _id += 1

                # 二级分类数据
                try:
                    print("正在请求数据的url:",p_link)
                    response3 = self.s.get(p_link,verify=False)
                    response3.encoding = "utf-8"
                    html_obj2 = etree.HTML(response3.text)
                    if "https://fuzhuang.1688.com/nvzhuang" == p_link:
                        three_product_name = html_obj2.xpath("//div[@class='ch-menu-item-list']/ul//a/text()")[:15]
                        three_product_link = html_obj2.xpath("//div[@class='zone-content fd-clr']/ul/li/a/@href")[:15]

                    elif "https://fuzhuang.1688.com/nanzhuang" == p_link:
                        three_product_name = html_obj2.xpath("//div[@class='ch-menu-item-list']/ul//a/text()")[:12]
                        three_product_link = html_obj2.xpath("//div[@class='zone-content fd-clr']/ul/li/a/@href")[:12]

                    else:
                        # 二级分类数据
                        three_product_name = html_obj2.xpath("//div[@class='zone-content fd-clr']/ul/li/a/text()")
                        three_product_link = html_obj2.xpath("//div[@class='zone-content fd-clr']/ul/li/a/@href")

                    if three_product_name == [] and three_product_link == []:
                        three_product_name = html_obj2.xpath("//div[@class='ch-menu-item-list']/ul//a/text() | //ul[@class='clear']/li/a/text()")
                        three_product_link = html_obj2.xpath("//div[@class='ch-menu-item-list']/ul//a/@href | //ul[@class='clear']/li/a/@href")

                    print(77777, three_product_link,'\n',three_product_name)
                    for s_name, s_link in zip([i.strip() for i in three_product_name], three_product_link):
                        if 'https:' not in s_link:
                            second_link = "https:" + s_link
                        else:
                            second_link = s_link

                        # 有重复的分类数据就退出
                        if s_name not in newCategory:
                            newCategory.add(s_name)
                            self.ali.insert_category(s_name, second_link, pid, 2, created_time)
                            _id += 1

                except Exception as e:
                    print "异常信息:",e
                    traceback.print_exc()

    # 解析数据规则
    def product_Data(self):
        sql = self.ali.get_categoryName2()
        json_url = "https://h5api.m.1688.com/h5/mtop.1688.offerservice.getoffers/1.0/?appKey=12574478&t=1531383212347&sign=b2e967a197e83f7ba300b7a60ec96d97&data=%7B%22fromMode%22%3A%22supportBack%22%2C%22keywords%22%3A%22%E8%A2%9C%E5%AD%90%22%2C%22appName%22%3A%22wap%22%2C%22beginPage%22%3A2%2C%22pageSize%22%3A20%7D"
        sort_type = {
            'pop': 1,
            'booked': 2,
        }
        for sort in sort_type.keys():
            sortId = sort_type[sort]
            for id_keyword in sql:
                self.s.get(json_url,verify=False)
                timestamp = int(time.time() * 1000)
                h5_tk = self.s.cookies.get_dict()
                print "cookies:", h5_tk
                first_string = h5_tk['_m_h5_tk'].split('_')[0]
                print "字符串__:", first_string
                try:
                    index = 0
                    flag = True
                    for num in range(1, 100):
                        if not flag:
                            break
                        data = '{{"sortType":"{}","keywords":"{}","descendOrder":"true","appName":"wap","beginPage":{},"pageSize":20}}'.format(sort, id_keyword[1], num)
                        string = "{}&{}&12574478&{}".format(first_string, timestamp, data)
                        sign = md5(string.encode('utf-8')).hexdigest()
                        product_link = 'https://h5api.m.1688.com/h5/mtop.1688.offerservice.getoffers/1.0/?appKey=12574478&t={}&sign={}&data={}'.format(timestamp, sign, data)
                        self.cookies = self.s.cookies.get_dict()

                        res = self.construct_requests(product_link)
                        product_id_list = self.product_id(res)

                        if product_id_list:
                            for pid in product_id_list:
                                detail_link = "https://m.1688.com/offer/{}.html?".format(pid)
                                res2 = self.construct_requests(detail_link, 1)
                                html_obj = etree.HTML(res2)

                                product_name = html_obj.xpath("//h1[@class='d-title']/span/text()")[0]
                                product_count_list = html_obj.xpath("//dl[@class='d-price-rangecount']/dd/text()")
                                price_list = html_obj.xpath(
                                    "//dl[@class='d-price-discount nobottom  ']/dd/text() | //dl[@class='d-price-discount  ']/dd/text()")

                                original_price = html_obj.xpath("//dl[@class='d-price-original']/dd/del/text()")  # 原价

                                # 图片url
                                p_info_json = html_obj.xpath('//*[@id="wing-page-content"]/div/script[2]//text()')[
                                                  0] + '&end&'
                                p_detail_info = re.findall(r'window.wingxViewData\[0\]=(.*)&end&', p_info_json)[0]
                                p_info_json = json.loads(p_detail_info)
                                image_list = jsonpath.jsonpath(p_info_json, expr='$..imageList[*].originalImageURI')

                                if product_count_list == [] and price_list == []:
                                    product_count_list = html_obj.xpath(
                                        "//dl[@class='d-price-discount larger nobottom']/dt/text() | //dl[@class='d-price-discount larger ']/dt/text()")
                                    price_list = html_obj.xpath(
                                        "//dl[@class='d-price-discount larger nobottom']/dd/text() | //dl[@class='d-price-discount larger ']/dd/text()")

                                sale_count = html_obj.xpath("//span[@class='saled-count']/text()")[0]  # 成交量
                                # 评价量
                                comment_totals = jsonpath.jsonpath(p_info_json, expr='$..rateTotals')[0]
                                # 评分
                                star_level = jsonpath.jsonpath(p_info_json, expr='$..rateAverageStarLevel')[0]

                                print "商品详情链接:", detail_link
                                print "商品名称:", product_name
                                image_link = str(image_list)
                                print "商品图片:", image_link
                                if sale_count:
                                    saleCount = sale_count.strip()
                                else:
                                    saleCount = ""
                                print "商品销量:", saleCount

                                price = ''
                                price_list2 = [i.strip() for i in price_list if len(i.strip()) > 1]
                                for k, l in zip(product_count_list, price_list2):
                                    price += '(' + k.strip() + ':' + l.strip() + '),'
                                print "起批量:商品价格", price

                                # atlas 专用价格
                                atlas_price = 0
                                try:
                                    atlas_price = int(float(price_list2[0]) * 100)
                                except:
                                    pass

                                # 原价
                                if original_price == []:
                                    count_price = ''
                                else:
                                    count_price = ''
                                    for count, o_price in zip(product_count_list, original_price):
                                        count_price += '(' + count + ':' + o_price + ')'

                                print "原价:", count_price
                                print "评价量:", comment_totals
                                print "评分__:", star_level
                                website_id = 2
                                created_time = time.strftime("%Y-%m-%d %H:%M:%S")

                                # 存储数据
                                self.ali.product_Data_1688(product_name, id_keyword[1], atlas_price, price, count_price, detail_link.replace('m.1688.com','detail.1688.com'), pid, index, website_id,
                                                     star_level, sortId, saleCount, image_link, id_keyword[0], comment_totals, created_time)

                                index += 1
                                if index > 1000:
                                    print "已经采集到第%s件商品:" % index
                                    flag = False
                                    break

                except Exception as e:
                    print "程序异常:", e
                    traceback.print_exc()

    def construct_requests(self, url, *args):
        try:
            mark = True
            if args and args[0] == 1:
                response = self.s.get(url, headers=self.headers, proxies=self.proxy, cookies=self.cookies, timeout=20)
                mark = re.findall(r'discountPriceRanges', response.text, re.S)
            else:
                response = self.s.get(url, proxies=self.proxy, headers=self.headers, cookies=self.cookies, timeout=30)

            if response.status_code == 200 and mark:
                return response.text
            else:
                raise Exception("请求异常____", response.status_code)

        except Exception as e:
            print "程序出现异常信息,需要处理~!", e
            FLAG = False
            if FLAG == False:
                for i in range(1, 8):
                    time.sleep(0.3)
                    print '%s 请求超时，进行第 %s 次重复请求' % (url, i)
                    if i == 2:
                        print "[INFO]:请求缓存中～～～～"
                        time.sleep(3)
                    if i == 3:
                        print "[INFO]:再次请求中，请稍等~~~~"
                        time.sleep(5)
                    if i == 7:
                        print "[INFO]最后一次请求发送中"
                        time.sleep(20)

                    try:
                        mark = True
                        print '[INFO]: 正在请求：', url
                        if args:
                            if args[0] == 1:
                                response = self.s.get(url, proxies=self.proxy, headers=self.headers,cookies=self.cookies, timeout=30)
                                mark = re.findall(r'discountPriceRanges', response.text, re.S)
                            else:
                                response = self.s.get(url, proxies=self.proxy, headers=self.headers,cookies=self.cookies, timeout=30)
                        else:
                            response = self.s.get(url, proxies=self.proxy, headers=self.headers, cookies=self.cookies,timeout=30)

                        if response.status_code == 200 and mark:
                            return response.text
                        else:
                            raise Exception("[INFO]: 请求异常！！！！！！", response.status_code)

                    except:
                        with open('alibaba.log', 'a') as f:
                            f.write('%s请求失败,继续发送请求 %s\n' % (url, time.ctime()))
                        print "[DEBUG]:第%s次请求失败，继续发送请求" % i
                        continue

                if self.state_code == 200:
                    with open('alibaba.log', 'a') as f:
                        f.write('%s发送成功--%s\n' % (url, time.ctime()))
                else:
                    with open('alibaba.log', 'a') as f:
                        f.write('%s_发送请求失败～--%s\n' % (url, time.ctime()))

    def product_id(self, res):
        dict_data = json.loads(res)
        allData = jsonpath.jsonpath(dict_data, "$..data.offers[*]")
        if allData:
            product_id_list = jsonpath.jsonpath(dict_data, "$..data.offers[*].id")
            return product_id_list


if __name__ == '__main__':
    alibaba = alibaba_spider()
    start = time.time()
    # alibaba.categoryData() # 分类数据
    alibaba.product_Data() # 商品数据
    end = time.time()
    print "采集共计用时:{}".format(end-start)
